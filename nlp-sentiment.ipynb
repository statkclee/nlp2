{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석 빅픽쳐\n",
    "\n",
    "- 참고문헌: [Text Analytics with Python_ A Practical Real-World Approach](https://www.amazon.com/Text-Analytics-Python-Real-World-Actionable/dp/148422387X)\n",
    "\n",
    "**감성분석(sentiment analysis)** 은 특정 주제에 대하여 저자의 견해를 이해하는 과정으로 정의된다. 감성분석은 또한 텍스트에서 담긴 감성에 대한 사항을 이해하고 예측하는 방법론을 통칭하는데 크게 다음과 같은 두가지 방법론 세부적으로 나누면 세가지 방법론으로 나눌 수도 있다.\n",
    "\n",
    "<img src=\"fig/sentiment-analysis-framework.png\" alt=\"감성분석\" width=\"77%\" />\n",
    "\n",
    "따라서 감성분석은 세가지 구성요소로 이뤄진다. 즉, 누가(저자) 어떤 주제(Subject)에 대한 견해(Opinion)와 감정(Emotion)을 텍스트에 담았는지 이해하고 예측하는 것이다.\n",
    "\n",
    "- 저자(Author)\n",
    "- 주제(Subject)\n",
    "- 견해(Opinion)/감정(Emotion)\n",
    "\n",
    "감성분석이 중요해지는 이유는 고객이나 유권자가 무슨 주제에 대해서 어떤 감정을 가지고 어떻게 텍스트를 통해서 정보를 주고 받는지 기계를 동원해서 이해해야 하는데 텍스트를 통한 데이터가 방대하다.\n",
    "\n",
    "- SNS\n",
    "- 콜센터\n",
    "- 제품/서비스 분석\n",
    "- 브랜드 평판 관리\n",
    "- ...\n",
    "\n",
    "또한, 텍스트 데이터가 다양한 형태로 존재하기 때문에 어떤 수준에서 분석할지도 고민할 필요가 있다.\n",
    "\n",
    "- 책/저널/카탈로그\n",
    "- 문서 (Document)\n",
    "- 문단 (Paragraph)\n",
    "- 문장 (Sentence)\n",
    "- 측면 (Aspect) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규칙/어휘 기반 감성분석\n",
    "\n",
    "규칙/어휘(lexicon) 기반 감성분석은 어휘(lexicon)에 기반하고 있기 때문에 전처리가 특히 중요하다.\n",
    "\n",
    "- 상당부분 텍스트 데이터를 인터넷을 통해 입수하기 때문에 HTML 태그와 같은 마크다운 문법과 연관된 태그는 모두 제거한다.\n",
    "- Non-Ascii 문자 액센트가 붙어있어 있는 단어를 어휘 사전에서 매칭이 가능한 형태로 변환시킨다; $\\^{o}$ &rarr; $o$\n",
    "- 축약된 단어 풀기; don't &rarr; do not, I'd &rarr; I would 혹은 I could\n",
    "- 특수문자 제거\n",
    "- 어근 추출(stemming) 혹은 표제어 추출(lemmatization)\n",
    "- 불용어 제거(stopwords)\n",
    "\n",
    "상기 전처리 작업이 완료된 후에야 파이썬에서 많이 사용되는 어휘사전(lexicon)을 활용하여 감성분석을 수행할 수 있다.\n",
    "\n",
    "- Bing Liu’s lexicon\n",
    "- MPQA subjectivity lexicon\n",
    "- Pattern lexicon\n",
    "- TextBlob lexicon\n",
    "- AFINN lexicon\n",
    "- SentiWordNet lexicon\n",
    "- VADER lexicon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing Lui 어휘사전\n",
    "\n",
    "Bing Lui 어휘사전은 6,800개 단어로 구성되어 있는데  `positive-words.txt`는 2,000 단어/구문, `negative-words.txt`에는 4,800 단어/구문이 포함되어 있다. [Opinion Mining, Sentiment Analysis, and Opinion Spam Detection](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon) 웹사이트에 자세한 내용을 확인할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TextBlob` 어휘사전\n",
    "\n",
    "[TextBlob, \"Tutorial: Quickstart\"](https://textblob.readthedocs.io/en/dev/quickstart.html)을 참조하여 `TextBlob` 클래스를 활용하여 감성분석을 수행할 수 있다. `TextBlob` 어휘사전은 [GitHub](https://github. com/sloria/TextBlob/blob/dev/textblob/en/en-sentiment.xml)에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of wiki:  Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment of wiki:  Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "\n",
    "# 감성 출력   \n",
    "print('Sentiment of wiki: ', wiki.sentiment)\n",
    "print('Sentiment of wiki: ', testimonial.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  sentiment                                               text\n",
       "0        1          0                       is so sad for my APL frie...\n",
       "1        2          0                     I missed the New Moon trail...\n",
       "2        3          1                            omg its already 7:30 :O\n",
       "3        4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4        5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/twitter_sentiment_train.csv\", encoding = \"ISO-8859-1\")\n",
    "df.columns = [\"item_id\", \"sentiment\", \"text\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "판다스 데이터프레임에 저장된 `text`를 쭉 뽑아서 `TextBlob` 어휘사전을 활용하여 각각의 감성을 추출해보자. 너무 많아서 5개만 추려서 실제 Sentiment와 감성점수(Predicted Sentiment polarity)를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0 : is so sad for my APL friend.............\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: -0.5\n",
      "------------------------------------------------------------\n",
      "Text 1 : I missed the New Moon trailer...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 0.13636363636363635\n",
      "------------------------------------------------------------\n",
      "Text 2 : omg its already 7:30 :O\n",
      "Sentiment: 1\n",
      "Predicted Sentiment polarity: 0.05\n",
      "------------------------------------------------------------\n",
      "Text 3 : .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 0.0\n",
      "------------------------------------------------------------\n",
      "Text 4 : i think mi bf is cheating on me!!!       T_T\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.loc[0:4, :].iterrows():\n",
    "    text = row['text']\n",
    "    print(f'Text {index} : {text.strip()}')\n",
    "    print('Sentiment:', row['sentiment'])\n",
    "    print('Predicted Sentiment polarity:', TextBlob(text).sentiment.polarity)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFINN 어휘사전\n",
    "\n",
    "AFINN 어휘사전은 감성분석에 가장 단순하면서도 많이 사용되는 어휘사전이다. [AFINN 어휘사전](https://github.com/fnielsen/afinn/tree/master/afinn/data)은 AFINN-11 버전을 Github에 올려놓고 `afinn` 라이브러리를 제작하여 공개했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0 : is so sad for my APL friend.............\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: -1.0\n",
      "------------------------------------------------------------\n",
      "Text 1 : I missed the New Moon trailer...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: -2.0\n",
      "------------------------------------------------------------\n",
      "Text 2 : omg its already 7:30 :O\n",
      "Sentiment: 1\n",
      "Predicted Sentiment polarity: 0.0\n",
      "------------------------------------------------------------\n",
      "Text 3 : .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: -1.0\n",
      "------------------------------------------------------------\n",
      "Text 4 : i think mi bf is cheating on me!!!       T_T\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: -3.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# !pip install afinn\n",
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)\n",
    "\n",
    "for index, row in df.loc[0:4, :].iterrows():\n",
    "    text = row['text']\n",
    "    print(f'Text {index} : {text.strip()}')\n",
    "    print('Sentiment:', row['sentiment'])\n",
    "    print('Predicted Sentiment polarity:', afn.score(text)\n",
    "         )\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER 어휘사전\n",
    "\n",
    "VADER(Valence Aware Dictionary and sEntiment Reasoner)에 대한 자세한 사항은 Hutto, C.J., and Gilbert, E.E. (2014),\"VADER:\n",
    "A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text\" fproceedings of the Eighth International Conference on Weblogs and Social Media (ICWSM-14).에서 확인할 수 있다. [VADER Github](https://github.com/cjhutto/vaderSentiment)에 공개되어 있으며 `nltk. sentiment.vader` 모듈에 구현되어 있어 이를 불러 사용해도 좋다.\n",
    " \n",
    "[Parul Pandey, \"Simplifying Sentiment Analysis using VADER in Python (on Social Media Text)\n",
    "Parul Pandey\"](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0 : is so sad for my APL friend.............\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: {'neg': 0.361, 'neu': 0.639, 'pos': 0.0, 'compound': -0.5256}\n",
      "Predicted Sentiment polarity Class: 0\n",
      "------------------------------------------------------------\n",
      "Text 1 : I missed the New Moon trailer...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: {'neg': 0.355, 'neu': 0.645, 'pos': 0.0, 'compound': -0.296}\n",
      "Predicted Sentiment polarity Class: 0\n",
      "------------------------------------------------------------\n",
      "Text 2 : omg its already 7:30 :O\n",
      "Sentiment: 1\n",
      "Predicted Sentiment polarity: {'neg': 0.348, 'neu': 0.652, 'pos': 0.0, 'compound': -0.2808}\n",
      "Predicted Sentiment polarity Class: 0\n",
      "------------------------------------------------------------\n",
      "Text 3 : .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: {'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'compound': -0.4767}\n",
      "Predicted Sentiment polarity Class: 0\n",
      "------------------------------------------------------------\n",
      "Text 4 : i think mi bf is cheating on me!!!       T_T\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: {'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compound': -0.6679}\n",
      "Predicted Sentiment polarity Class: 0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ! pip install vaderSentiment\n",
    "# import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_polarity(text):\n",
    "    \"\"\" Transform the output to a binary 0/1 result \"\"\"\n",
    "    score = analyser.polarity_scores(text)\n",
    "    return 1 if score['pos'] > score['neg'] else 0\n",
    "\n",
    "for index, row in df.loc[0:4, :].iterrows():\n",
    "    text = row['text']\n",
    "    print(f'Text {index} : {text.strip()}')\n",
    "    print('Sentiment:', row['sentiment'])\n",
    "    print('Predicted Sentiment polarity:', analyser.polarity_scores(text))\n",
    "    print('Predicted Sentiment polarity Class:', vader_polarity(text))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet 어휘사전\n",
    "\n",
    "WordNet은 영어에 대한 가장 인기있는 말뭉치 중 하나다. WordNet은 자연어처리와 의미론 분석(semantic analysis)에 많이 활용되고, SentiWordNet 어휘사전은 감성분석에 자주 사용된다. [SentiWordNet](http://sentiwordnet.isti.cnr.it/) 웹사이트를 통해 자세한 사항을 접할 수 있으며 역시 `nltk` 라이브러리를 활용해서 활용이 가능하다.\n",
    "\n",
    "- [nlpforhackers.io, \"Getting Started with Sentiment Analysis\"](https://nlpforhackers.io/sentiment-analysis-intro/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0 : is so sad for my APL friend.............\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 0\n",
      "------------------------------------------------------------\n",
      "Text 1 : I missed the New Moon trailer...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 1\n",
      "------------------------------------------------------------\n",
      "Text 2 : omg its already 7:30 :O\n",
      "Sentiment: 1\n",
      "Predicted Sentiment polarity: 1\n",
      "------------------------------------------------------------\n",
      "Text 3 : .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 1\n",
      "------------------------------------------------------------\n",
      "Text 4 : i think mi bf is cheating on me!!!       T_T\n",
      "Sentiment: 0\n",
      "Predicted Sentiment polarity: 1\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('sentiwordnet')\n",
    "    \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    " \n",
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    " \n",
    " \n",
    "def clean_text(text):\n",
    "    text = text.replace(\"<br />\", \" \")\n",
    "#     text = text.decode(\"utf-8\")\n",
    "    return text\n",
    " \n",
    " \n",
    "def swn_polarity(text):\n",
    "    \"\"\"\n",
    "    Return a sentiment polarity: 0 = negative, 1 = positive\n",
    "    \"\"\"\n",
    " \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    " \n",
    "    text = clean_text(text)\n",
    " \n",
    " \n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    " \n",
    "        for word, tag in tagged_sentence:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    " \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    " \n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    " \n",
    "            # Take the first sense, the most common\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    " \n",
    "            sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "            tokens_count += 1\n",
    " \n",
    "    # judgment call ? Default to positive or negative\n",
    "    if not tokens_count:\n",
    "        return 0\n",
    " \n",
    "    # sum greater than 0 => positive sentiment\n",
    "    if sentiment >= 0:\n",
    "        return 1\n",
    " \n",
    "    # negative sentiment\n",
    "    return 0\n",
    " \n",
    " \n",
    "for index, row in df.loc[0:4, :].iterrows():\n",
    "    text = row['text']\n",
    "    print(f'Text {index} : {text.strip()}')\n",
    "    print('Sentiment:', row['sentiment'])\n",
    "    print('Predicted Sentiment polarity:', swn_polarity(text))\n",
    "    print('-'*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
