{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트위터 감성 예측\n",
    "\n",
    "## 데이터셋\n",
    "\n",
    "캐글웹사이트 [Twitter sentiment analysis](https://www.kaggle.com/c/twitter-sentiment-analysis2) 경쟁 웹사이트에서 트위터 감성분석 데이터를 다운로드 받는다. \n",
    "\n",
    "## 작업흐름도\n",
    "\n",
    "트위터 감성 예측을 위해서 $X$ 와 $y$를 확실히 구분하는 예측모형이 필요하고 $X$가 트위터와 같은 텍스트라도 이를 숫자로 변환시켜 예측모형을 구축하는 것이 가능하다. 특히 예측모형의 성능은 예측모형 자체로도 의미가 성능을 높일 수 있지만 그보다도 **Feature**를 발굴하여 넣어주는 것이 경우에 따라서 더 좋은 성능에 영향을 준다고 알려져 있다.\n",
    "\n",
    "<img src=\"fig/twitter-sentiment-ml.png\" alt=\"트위터 감성분석 예측모형\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 가져오기\n",
    "\n",
    "가장 먼저 트위터 웹사이트에서 다운로드 받은 감성분류 데이터를 판다스로 불러온다.\n",
    "\n",
    "> **`UnicodeDecodeError when reading CSV file in Pandas with Python` 오류**\n",
    "> \n",
    "> 인코딩이 문제라 `read_csv()` 메쏘드에 `encoding = \"ISO-8859-1\"`을 넣어주거나, `encoding = \"utf-8\"`을 넣어주면 문제가 많이 해결된다.\n",
    "> https://stackoverflow.com/questions/18171739/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python\n",
    "\n",
    "데이터가 여러 사람의 노력으로 라벨(label)이 `Sentiment` 변수에 0 혹은 1로 코딩되어 있고 데이터 사전에는 다음과 같이 데이터셋을 설명하고 있다.\n",
    "\n",
    "- ItemID - id of twit\n",
    "- Sentiment - sentiment\n",
    "    - 0 : negative\n",
    "    - 1 : positive\n",
    "- SentimentText - text of the twit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  sentiment                                               text\n",
       "0        1          0                       is so sad for my APL frie...\n",
       "1        2          0                     I missed the New Moon trail...\n",
       "2        3          1                            omg its already 7:30 :O\n",
       "3        4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4        5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/twitter_sentiment_train.csv\", encoding = \"ISO-8859-1\")\n",
    "df.columns = [\"item_id\", \"sentiment\", \"text\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "피처공학(Feature Engineering) 단계를 통해서 `SentimentText` 텍스트에서 다양한 Feature를 추출해 보자.\n",
    "\n",
    "## 텍스트 통계\n",
    "\n",
    "단어갯수, 평균 단어 길이 등 기초적인 텍스트 통계를 사용하여 트위터 텍스트 감성을 분류하는 예측모형을 제작해보자.\n",
    "먼저 트위터 전체 문장의 문자갯수가 얼마나 되는지 `len` 함수를 사용하고, 단어 갯수를 계산하는 경우 `len` 내장함수와 같은 역할을 수행하는 함수가 없어 `count_words()` 도움함수를 간단히 작성하여 Feature를 산출해 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>char_cnt</th>\n",
       "      <th>word_cnt</th>\n",
       "      <th>hashtag_cnt</th>\n",
       "      <th>mention_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>@Cupcake  seems like a repeating problem   hop...</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake__ arrrr we both replied to each other...</td>\n",
       "      <td>138</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>@CuPcAkE_2120 ya i thought so</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>@Cupcake_Dollie Yes. Yes. I'm glad you had mor...</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake_kayla haha yes you do</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  sentiment                                               text  \\\n",
       "99984    99996          0  @Cupcake  seems like a repeating problem   hop...   \n",
       "99985    99997          1  @cupcake__ arrrr we both replied to each other...   \n",
       "99986    99998          0                     @CuPcAkE_2120 ya i thought so    \n",
       "99987    99999          1  @Cupcake_Dollie Yes. Yes. I'm glad you had mor...   \n",
       "99988   100000          1                    @cupcake_kayla haha yes you do    \n",
       "\n",
       "       char_cnt  word_cnt  hashtag_cnt  mention_cnt  \n",
       "99984        78        12            0            1  \n",
       "99985       138        26            0            1  \n",
       "99986        30         5            0            1  \n",
       "99987        61        11            0            1  \n",
       "99988        31         5            0            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 문자갯수\n",
    "df['char_cnt'] = df['text'].apply(len)\n",
    "\n",
    "# 2. 단어갯수\n",
    "def count_words(text):\n",
    "    ''' \n",
    "        문장을 입력받아 단어갯수를 반환한다.\n",
    "    '''\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "df['word_cnt'] = df['text'].apply(count_words)\n",
    "\n",
    "# 3. 해쉬태그(#) 갯수\n",
    "def count_hashtag(text):\n",
    "    ''' \n",
    "        문장을 입력받아 해쉬태그(#)를 센다\n",
    "    '''\n",
    "    words = text.split()\n",
    "    \n",
    "    hashtags = [word for word in words if word.startswith('#')]\n",
    "    return len(hashtags)\n",
    "\n",
    "df['hashtag_cnt'] = df['text'].apply(count_hashtag)\n",
    "\n",
    "# 4. 언급(@) 갯수\n",
    "def count_mention(text):\n",
    "    ''' \n",
    "        문장을 입력받아 언급횟수(@)를 센다\n",
    "    '''\n",
    "    words = text.split()\n",
    "    \n",
    "    mentions = [word for word in words if word.startswith('@')]\n",
    "    return len(mentions)\n",
    "\n",
    "df['mention_cnt'] = df['text'].apply(count_mention)\n",
    "\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트위터 트윗에서 내장된 `len` 함수와 `count_mention`, `count_hashtag`, `count_words`와 같은 사용자 정의 함수를 통해서 기초적인 텍스트 Feature를 추출해냈다. 이를 바탕으로 감성분류기 성능이 어느 정도 나오는지 예측 모형을 생성해보자.\n",
    "나이브 베이즈 예측모형을 훈련/시험 데이터로 분리하고 이를 적합시켜 나온 예측모형 정확도를 통해 기준모형으로 삼아도 좋을 듯 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: 0.576\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 모형\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련/시험 데이터 분리\n",
    "string_df = df[['char_cnt', 'word_cnt', 'hashtag_cnt', 'mention_cnt']]\n",
    "\n",
    "target = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(string_df, target, test_size=0.3)\n",
    "\n",
    "# 예측모형 적합\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 읽기 점수(readability score)\n",
    "\n",
    "영어문장에 대해 읽기 점수(readability score) 측정하여 이를 Feature로 넣어 예측모형 정확도를 높여나간다. 이를 위해서 [Flesch–Kincaid readability tests](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests) 사례를 들면 다음 공식에 의해서 읽기 점수가 부여된다.\n",
    "\n",
    "$$206.835 - 1.015 \\left( \\frac{\\text{total words}}{\\text{total sentences}} \\right) - 84.6 \\left( \\frac{\\text{total syllables}}{\\text{total words}} \\right)$$\n",
    "\n",
    "|    점수\t | 학년   |             설명        |\n",
    "|----------|--------|---------------------------|\n",
    "| 100-90   | 5학년  | 읽기 쉽고, 11살 학생도 쉽게 이해함 |\n",
    "| 90–80\t   | 6학년  | 읽기 쉽고, 고객을 위한 대화형태 영어 |\n",
    "| 80–70  | 중1(7th grade) | 상당히 읽기 쉬움 |\n",
    "| 70–60  | 중2,3(8th & 9th grade) | 평이한 영문, 13 ~ 15세 학생도 쉽게 이해함 | students.\n",
    "| 60–50  | 고등학생 | 나름 읽기 어려움 |\n",
    "| 50–30  | 대학생   | 읽기 어려움 |\n",
    "| 30–0   | 대학원생 | 매우 읽기 어려움, 대학원생은 잘 이해함 |\n",
    "\n",
    "읽기 점수 계산을 위해서 `textatistic` 라이브러리가 필요한데 다음 명령어를 쉘에서 입력하게 되면 수월하게 설치할 수 있다.\n",
    "\n",
    "$ `pip install textatistic`\n",
    "\n",
    "[stackoverflow](https://stackoverflow.com/questions/46109166/converting-categorizedplaintextcorpusreader-into-dataframe?noredirect=1&lq=1)를 참조하여 영화 리뷰데이터를 가져와서 읽기 점수를 산출해본다. [textatistic 0.0.1](https://pypi.org/project/textatistic/)을 참조하면 다양한 읽기점수 통계량을 확인할 수 있다.\n",
    "\n",
    "- `dalechall_score`: Dale-Chall score.\n",
    "- `flesch_score`: Flesch Reading Ease score.\n",
    "- `fleschkincaid_score`: Flesch-Kincaid score.\n",
    "- `gunningfog_score` : Gunning Fog score.\n",
    "- `smog_score`: SMOG score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv000_29416.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv001_19502.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv002_17424.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv003_12683.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv004_12641.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  tag                                               text\n",
       "0  cv000_29416.txt  neg  truman ( \" true-man \" ) burbank is the perfect...\n",
       "1  cv001_19502.txt  neg  truman ( \" true-man \" ) burbank is the perfect...\n",
       "2  cv002_17424.txt  neg  truman ( \" true-man \" ) burbank is the perfect...\n",
       "3  cv003_12683.txt  neg  truman ( \" true-man \" ) burbank is the perfect...\n",
       "4  cv004_12641.txt  neg  truman ( \" true-man \" ) burbank is the perfect..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "from textatistic import Textatistic\n",
    "\n",
    "# 읽기점수 산출 함수\n",
    "def calc_readability(text):\n",
    "    readability_scores = Textatistic(text).scores\n",
    "    score = readability_scores['fleschkincaid_score']\n",
    "    return score\n",
    "\n",
    "# 영화 리뷰 데이터 \n",
    "reviews = []\n",
    "\n",
    "for file_id in mr.fileids():\n",
    "    tag, filename = file_id.split('/')\n",
    "    reviews.append((filename, tag, mr.raw(fileid)))\n",
    "\n",
    "movie_df = pd.DataFrame(reviews, columns=['filename', 'tag', 'text'])\n",
    "\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "      <th>fleschkincaid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>cv934_20426.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>6.449003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>cv767_14062.txt</td>\n",
       "      <td>pos</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>6.449003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>cv459_21834.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>6.449003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>cv445_25882.txt</td>\n",
       "      <td>pos</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>6.449003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>cv341_25667.txt</td>\n",
       "      <td>neg</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>6.449003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  tag                                               text  \\\n",
       "934   cv934_20426.txt  neg  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "1767  cv767_14062.txt  pos  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "459   cv459_21834.txt  neg  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "1445  cv445_25882.txt  pos  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "341   cv341_25667.txt  neg  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "\n",
       "      fleschkincaid_score  \n",
       "934              6.449003  \n",
       "1767             6.449003  \n",
       "459              6.449003  \n",
       "1445             6.449003  \n",
       "341              6.449003  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_movie_df = movie_df.sample(n=10)\n",
    "\n",
    "sample_movie_df['fleschkincaid_score'] = sample_movie_df['text'].apply(calc_readability)\n",
    "sample_movie_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
