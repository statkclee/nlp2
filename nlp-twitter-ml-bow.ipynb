{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW(Bag of Words)\n",
    "\n",
    "트위터 감성을 분류하는데 트위터 텍스트를 사전에 정제할 필요가 있다. \n",
    "이를 위해서 `spacy` 라이브러리를 활용하는데 `clean_text()` 사용자 정의 함수를 만들어서 표제어 추출(lemmatization) 작업을 수행해서 이를 BoW(Bag of Words)에 넣어 트위터 감성 분류하는데 사용할 예측모형을 개발한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트위터 데이터 가져오기\n",
    "\n",
    "먼저 트위터 텍스트 데이터를 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/twitter_sentiment_train.csv\", encoding = \"ISO-8859-1\")\n",
    "smpl_df = df.sample(1000, random_state = 77777)\n",
    "smpl_df.columns = [\"item_id\", \"sentiment\", \"text\"]\n",
    "smpl_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 정제\n",
    "\n",
    "텍스트를 정제하는 기법은 여러가지가 있지만, 아래 `clean_text()` 사용자 정의 함수를 만들어서 표제어 추출(lemmatization) 작업을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Version: 2.1.4\n",
      "16392                                             football\n",
      "92027    unfortunately thumb drive crash Windows Explor...\n",
      "82269                    Lol place awesome buy annual pass\n",
      "83920                                                 miss\n",
      "37637                                     sweet hello long\n",
      "Name: lemma_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(f\"spaCy Version: {spacy.__version__}\")\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def clean_text(text):\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in spacy_stopwords]\n",
    "    return ' '.join(a_lemmas)\n",
    "  \n",
    "smpl_df['lemma_text'] = smpl_df['text'].apply(clean_text)\n",
    "print(smpl_df['lemma_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW 모형\n",
    "\n",
    "BoW 모형을 `sklearn` 라이브러리 `CountVectorizer` 클래스를 사용해서 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CountVectorizer` 클래스\n",
    "\n",
    "`CountVectorizer` 클래스를 활용하여 앞서 표제어 추출한 칼럼('lemma_text')을 BoW 객체로 변환시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2325)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "\n",
    "twitter_bow = vectorizer.fit_transform(smpl_df['lemma_text'])\n",
    "\n",
    "print(twitter_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW 변환이 제대로 되었는지를 확인하기 위해서 BoW를 데이터프레임으로 변환시킨다.\n",
    "그리고 나서 `get_feature_names()` 메쏘드를 호출해서 변환시킨 판다스 데이터프레임 칼럼명으로 넣어 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aarooonnnn  abandon  able  absolute  absolutely  access  accompany  \\\n",
      "0           0        0     0         0           0       0          0   \n",
      "1           0        0     0         0           0       0          0   \n",
      "2           0        0     0         0           0       0          0   \n",
      "3           0        0     0         0           0       0          0   \n",
      "4           0        0     0         0           0       0          0   \n",
      "\n",
      "   account  ace  ache  ...    yu  yuk  yummmm  yummy  yung  yup  zac  zealand  \\\n",
      "0        0    0     0  ...     0    0       0      0     0    0    0        0   \n",
      "1        0    0     0  ...     0    0       0      0     0    0    0        0   \n",
      "2        0    0     0  ...     0    0       0      0     0    0    0        0   \n",
      "3        0    0     0  ...     0    0       0      0     0    0    0        0   \n",
      "4        0    0     0  ...     0    0       0      0     0    0    0        0   \n",
      "\n",
      "   zombie  zurah  \n",
      "0       0      0  \n",
      "1       0      0  \n",
      "2       0      0  \n",
      "3       0      0  \n",
      "4       0      0  \n",
      "\n",
      "[5 rows x 2325 columns]\n"
     ]
    }
   ],
   "source": [
    "twitter_bow_df = pd.DataFrame(twitter_bow.toarray())\n",
    "\n",
    "twitter_bow_df.columns = vectorizer.get_feature_names()\n",
    "\n",
    "print(twitter_bow_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈 예측모형\n",
    "\n",
    "표제어 추출을 통해서 나름 전처리가 완료된 트위터 텍스트를 `BoW` 모형으로 Feature를 추출해 낼 수 있는 준비가 완료되었기에 다음 단계로 나이브 베이즈 예측모형에 넣어 예측모형의 성능을 비교해 본다.\n",
    "\n",
    "먼저 훈련/시험 데이터로 나누고 앞서 정제한 표제어 추출 칼럼('lemma_text')을 `CountVectorizer` 클래스를 통해서 BoW 객체로 만들고 이를 나이브 베이즈로 예측정확도를 높여본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: 0.603\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 모형\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련/시험 데이터 분리\n",
    "feature_df = smpl_df[['lemma_text']]\n",
    "\n",
    "target = smpl_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(feature_df, target, test_size=0.3)\n",
    "\n",
    "# BoW Feature \n",
    "vect = CountVectorizer(analyzer='word')\n",
    "\n",
    "X_train_bow = vect.fit_transform(X_train['lemma_text'])\n",
    "X_test_bow = vect.transform(X_test['lemma_text'])\n",
    "\n",
    "# 예측모형 적합\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "print(f\"시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 통계 지표 + BoW\n",
    "\n",
    "[트위터 감성 예측 - 텍스트 통계지표](nlp-twitter-ml) 모형에 BoW를 결합시켜 예측모형의 정확도를 높여본다.\n",
    "\n",
    "<img src=\"fig/nlp-ml-feature-bow.png\" alt=\"텍스트 통계지표 + BoW\" width=\"57%\" />\n",
    "\n",
    "## 텍스트 통계 지표\n",
    "\n",
    "텍스트 통계 지표를 [트위터 감성 예측 - 텍스트 통계지표](nlp-twitter-ml)에서 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>char_cnt</th>\n",
       "      <th>hashtag_cnt</th>\n",
       "      <th>word_cnt</th>\n",
       "      <th>mention_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16392</th>\n",
       "      <td>football</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92027</th>\n",
       "      <td>unfortunately thumb drive crash Windows Explor...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82269</th>\n",
       "      <td>Lol place awesome buy annual pass</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83920</th>\n",
       "      <td>miss</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37637</th>\n",
       "      <td>sweet hello long</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lemma_text  char_cnt  \\\n",
       "16392                                           football         8   \n",
       "92027  unfortunately thumb drive crash Windows Explor...        67   \n",
       "82269                  Lol place awesome buy annual pass        33   \n",
       "83920                                               miss         4   \n",
       "37637                                   sweet hello long        16   \n",
       "\n",
       "       hashtag_cnt  word_cnt  mention_cnt  \n",
       "16392            0         1            0  \n",
       "92027            0        10            0  \n",
       "82269            0         6            0  \n",
       "83920            0         1            0  \n",
       "37637            0         3            0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################\n",
    "# 텍스트 통계지표\n",
    "####################################################################\n",
    "# 1. 문자갯수\n",
    "# df['char_cnt'] = df['text'].apply(len)\n",
    "\n",
    "# 2. 단어갯수\n",
    "def count_words(text):\n",
    "    ''' \n",
    "        문장을 입력받아 단어갯수를 반환한다.\n",
    "    '''\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "# 3. 해쉬태그(#) 갯수\n",
    "def count_hashtag(text):\n",
    "    ''' \n",
    "        문장을 입력받아 해쉬태그(#)를 센다\n",
    "    '''\n",
    "    words = text.split()\n",
    "    \n",
    "    hashtags = [word for word in words if word.startswith('#')]\n",
    "    return len(hashtags)\n",
    "\n",
    "# 4. 언급(@) 갯수\n",
    "def count_mention(text):\n",
    "    ''' \n",
    "        문장을 입력받아 언급횟수(@)를 센다\n",
    "    '''\n",
    "    words = text.split()\n",
    "    \n",
    "    mentions = [word for word in words if word.startswith('@')]\n",
    "    return len(mentions)\n",
    "\n",
    "feature_df = smpl_df[['lemma_text']]\n",
    "\n",
    "feature_df['char_cnt'] = feature_df['lemma_text'].apply(len)\n",
    "feature_df['hashtag_cnt'] = feature_df['lemma_text'].apply(count_hashtag)\n",
    "feature_df['word_cnt'] = feature_df['lemma_text'].apply(count_words)\n",
    "feature_df['mention_cnt'] = feature_df['lemma_text'].apply(count_mention)\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW 모형\n",
    "\n",
    "BoW 모형을 다시 나이브베이즈 예측모형과 결합시켜 예측력을 높여본다.\n",
    "이를 위해서 몇가지 사전 작업을 다음과 같이 진행한다.\n",
    "\n",
    "1. `CountVectorizer()` 생성자를 사용해서 BoW 객체를 생성한다.\n",
    "1. `cv.fit_transform()`은 훈련데이터에 적용하고, `cv.transform()`은 시험데이터에 적용시킨다.\n",
    "1. BoW 객체를 X_train_bow.toarray()와 같이 `.toarray()` 메쏘드를 통해서 배열로 변환시킨 후에 데이터프레임으로 변환시킨다.\n",
    "    - `.reset_index(drop=True, inplace=True)` 메쏘드를 통해서 두 데이터프레임 행결합을 준비한다.\n",
    "1. `pd.concat()` 메쏘드를 통해서 두 데이터프레임을 결합시킨다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 1817) (300, 1821)\n"
     ]
    }
   ],
   "source": [
    "# 훈련/시험 데이터 분리\n",
    "X_train, X_test, y_train, y_test  = train_test_split(feature_df, target, test_size=0.3)\n",
    "\n",
    "# BoW 생성자 \n",
    "# cv = CountVectorizer(min_df=0.01, max_df=0.99)\n",
    "cv = CountVectorizer(analyzer='word')\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['lemma_text'])\n",
    "X_test_bow = cv.transform(X_test['lemma_text'])\n",
    "\n",
    "# 훈련 데이터: 통계 데이터프레임 + BoW 데이터프레임 ----- \n",
    "X_train_vect_df = pd.DataFrame(X_train_bow.toarray(), columns=cv.get_feature_names()).add_prefix('Count_')\n",
    "\n",
    "## 인덱스 정리\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_train_vect_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## 통계 + BoW 결합\n",
    "X_train_concat_df = pd.concat([X_train.drop(['lemma_text'], axis=1), X_train_vect_df], axis=1, sort=False)\n",
    "X_train_concat_df = X_train_concat_df.fillna(0)\n",
    "\n",
    "\n",
    "# 시험 데이터: 통계 데이터프레임 + BoW 데이터프레임 -----\n",
    "X_test_vect_df = pd.DataFrame(X_test_bow.toarray(), columns=cv.get_feature_names()).add_prefix('Count_')\n",
    "\n",
    "## 인덱스 정리\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test_vect_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## 통계 + BoW 결합\n",
    "X_test_concat_df = pd.concat([X_test.drop(['lemma_text'], axis=1), X_test_vect_df], axis=1, sort=False)\n",
    "X_test_concat_df = X_test_concat_df.fillna(0)\n",
    "\n",
    "print(X_train_vect_df.shape, X_test_concat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_cnt</th>\n",
       "      <th>hashtag_cnt</th>\n",
       "      <th>word_cnt</th>\n",
       "      <th>mention_cnt</th>\n",
       "      <th>Count_aarooonnnn</th>\n",
       "      <th>Count_abandon</th>\n",
       "      <th>Count_able</th>\n",
       "      <th>Count_absolute</th>\n",
       "      <th>Count_absolutely</th>\n",
       "      <th>Count_access</th>\n",
       "      <th>...</th>\n",
       "      <th>Count_youuu</th>\n",
       "      <th>Count_yr</th>\n",
       "      <th>Count_yu</th>\n",
       "      <th>Count_yuk</th>\n",
       "      <th>Count_yummy</th>\n",
       "      <th>Count_yung</th>\n",
       "      <th>Count_yup</th>\n",
       "      <th>Count_zac</th>\n",
       "      <th>Count_zealand</th>\n",
       "      <th>Count_zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_cnt  hashtag_cnt  word_cnt  mention_cnt  Count_aarooonnnn  \\\n",
       "0         4            0         1            0                 0   \n",
       "1         7            0         2            0                 0   \n",
       "2        33            0         6            0                 0   \n",
       "3         4            0         1            0                 0   \n",
       "4        13            0         2            0                 0   \n",
       "\n",
       "   Count_abandon  Count_able  Count_absolute  Count_absolutely  Count_access  \\\n",
       "0              0           0               0                 0             0   \n",
       "1              0           0               0                 0             0   \n",
       "2              0           0               0                 0             0   \n",
       "3              0           0               0                 0             0   \n",
       "4              0           0               0                 0             0   \n",
       "\n",
       "       ...       Count_youuu  Count_yr  Count_yu  Count_yuk  Count_yummy  \\\n",
       "0      ...                 0         0         0          0            0   \n",
       "1      ...                 0         0         0          0            0   \n",
       "2      ...                 0         0         0          0            0   \n",
       "3      ...                 0         0         0          0            0   \n",
       "4      ...                 0         0         0          0            0   \n",
       "\n",
       "   Count_yung  Count_yup  Count_zac  Count_zealand  Count_zombie  \n",
       "0           0          0          0              0             0  \n",
       "1           0          0          0              0             0  \n",
       "2           0          0          0              0             0  \n",
       "3           0          0          0              0             0  \n",
       "4           0          0          0              0             0  \n",
       "\n",
       "[5 rows x 1821 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 통계지표가 담긴 데이터프레임(X_train, X_test)과 BoW 모형이 결합된 데이터프레임을 결합시킨 후에 예측모형에 적합시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: 0.640\n"
     ]
    }
   ],
   "source": [
    "# 예측모형 적합\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# 분류모형 적합\n",
    "clf.fit(X_train_concat_df, y_train)\n",
    "\n",
    "# 모형 정확도\n",
    "accuracy = clf.score(X_test_concat_df, y_test)\n",
    "print(f\"시험 데이터셋으로 검정한 감성 분류 예측모형 정확도: {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
